{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevenpixler/hiLine/blob/main/HiLineMatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuFJLCWFtZbV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H1JxyMRujci",
        "outputId": "78e2ce00-935a-4e59-c484-d3080cd7e71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G2PqO5-wBPu"
      },
      "outputs": [],
      "source": [
        "# Define the root directory where your data is stored.\n",
        "data_root = r'/content/drive/MyDrive/HiLineTrainingData'\n",
        "\n",
        "# Create a list of classes (subdirectories) in your data directory.\n",
        "classes = os.listdir(data_root)\n",
        "\n",
        "# Initialize empty lists to store training and testing datasets.\n",
        "train_data = []  # List to store training data file paths.\n",
        "test_data = []   # List to store testing data file paths.\n",
        "\n",
        "# Define the ratio for splitting the data (e.g., 70% training, 30% testing).\n",
        "train_ratio = 0.75\n",
        "\n",
        "# Iterate through each class (subdirectory) in the data directory.\n",
        "for class_name in classes:\n",
        "    class_dir = os.path.join(data_root, class_name)  # Full path to the class directory.\n",
        "    class_images = os.listdir(class_dir)  # List of image file names in the class directory.\n",
        "\n",
        "    # Split the class images into training and testing sets using train_test_split.\n",
        "    train_images, test_images = train_test_split(class_images, train_size=train_ratio, random_state=42)\n",
        "\n",
        "    # Add the full path to each image in the class directory to the corresponding lists.\n",
        "    train_data.extend([os.path.join(class_dir, image) for image in train_images])  # Training data file paths.\n",
        "    test_data.extend([os.path.join(class_dir, image) for image in test_images])     # Testing data file paths.\n",
        "\n",
        "# Define the data transformations as in your original code.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 pixels.\n",
        "    transforms.ToTensor(),          # Convert images to PyTorch tensors.\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize pixel values.\n",
        "])\n",
        "\n",
        "# Create datasets and data loaders for training and testing.\n",
        "batch_size = 4\n",
        "\n",
        "# Create a training dataset and data loader.\n",
        "trainset = datasets.ImageFolder(data_root, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Create a testing dataset and data loader.\n",
        "testset = datasets.ImageFolder(data_root, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define class labels as in your original code.\n",
        "labels = classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hejm9kxg_po"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained ResNet model\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "# Get the number of features in the last layer of the ResNet model\n",
        "num_ftrs = resnet.fc.in_features\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes in your dataset\n",
        "resnet.fc = nn.Linear(num_ftrs, len(classes))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "MkJrymxZlICi",
        "outputId": "8165de23-f130-4160-e363-5191b9f1f4e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-72804891b3c6>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Train the model using the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_correct_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-72804891b3c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass the inputs through the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagate the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update the model's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "def train(net, trainloader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0  # Initialize the running loss\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data  # Get the inputs and labels from the data loader\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = net(inputs)  # Pass the inputs through the neural network\n",
        "            loss = criterion(outputs, labels)  # Calculate the loss\n",
        "            loss.backward()  # Backpropagate the gradients\n",
        "            optimizer.step()  # Update the model's parameters\n",
        "\n",
        "            running_loss += loss.item()  # Add the loss to the running total\n",
        "            if i % 100 == 99:  # Print every 100 batches\n",
        "                print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}\")  # Print the average loss\n",
        "                running_loss = 0.0  # Reset the running loss\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 15\n",
        "\n",
        "# Train the model using the training data\n",
        "train(resnet, trainloader, criterion, optimizer, num_epochs)\n",
        "\n",
        "def evaluate(net, testloader, num_correct_examples=5):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    correct_examples = []\n",
        "\n",
        "    # Start of the evaluation function. It takes a neural network (net),\n",
        "    # a data loader for the test set (testloader), and an optional argument\n",
        "    # for the number of correctly classified examples to display.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Use \"torch.no_grad()\" to disable gradient tracking, as we are not\n",
        "        # interested in computing gradients during evaluation.\n",
        "\n",
        "        for data in testloader:\n",
        "            # Iterate through the test data loader, which provides batches\n",
        "            # of test images and their corresponding labels.\n",
        "\n",
        "            inputs, labels = data\n",
        "            # Get the inputs (images) and their true labels from the current batch.\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            # Pass the inputs through the neural network to get predicted outputs.\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            # Determine the predicted labels by selecting the class with\n",
        "            # the highest probability for each input image.\n",
        "\n",
        "            total += labels.size(0)\n",
        "            # Increment the 'total' count by the number of labels in the batch.\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            # Increment the 'correct' count by the number of correctly predicted\n",
        "            # labels in the batch.\n",
        "\n",
        "            if len(correct_examples) < num_correct_examples:\n",
        "                # If we haven't collected enough examples yet,\n",
        "                correct_mask = predicted == labels\n",
        "                # Create a mask to identify correct predictions in the batch.\n",
        "                for i in range(len(correct_mask)):\n",
        "                    if correct_mask[i]:\n",
        "                        # Iterate through the mask and add correctly classified\n",
        "                        # examples to the 'correct_examples' list.\n",
        "                        image = inputs[i].permute(1, 2, 0)\n",
        "                        # Extract the image and permute the dimensions to be suitable\n",
        "                        # for displaying with Matplotlib.\n",
        "                        true_label = labels[i].item()\n",
        "                        # Get the true label for the image.\n",
        "                        predicted_label = predicted[i].item()\n",
        "                        # Get the predicted label for the image.\n",
        "                        correct_examples.append((image, true_label, predicted_label))\n",
        "                        # Append the correctly classified example as a tuple.\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    # Calculate the accuracy as the percentage of correctly classified examples.\n",
        "    print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
        "    # Print the accuracy on the test set.\n",
        "\n",
        "    print(\"Correctly classified examples:\")\n",
        "    # Print a message to indicate that the following lines will display\n",
        "    # correctly classified examples.\n",
        "\n",
        "    for i, (image, true_label, predicted_label) in enumerate(correct_examples):\n",
        "        if i >= num_correct_examples:\n",
        "            break\n",
        "        # Iterate through the collected correct examples and display them.\n",
        "        plt.imshow(image)\n",
        "        # Display the image using Matplotlib.\n",
        "        plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "        # Set the title of the displayed image to show the true and predicted labels.\n",
        "        plt.show()\n",
        "        # Show the image with the title.\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "evaluate(resnet, testloader)\n",
        "\n",
        "# Define a path to save the model\n",
        "PATH = \"hiline_class.pt\"\n",
        "\n",
        "# Save the modified model state_dict after training\n",
        "torch.save(resnet.state_dict(), PATH)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GrtZQS1Tc_r2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}